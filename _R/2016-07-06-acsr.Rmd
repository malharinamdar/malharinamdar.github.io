---
layout: post
title: "R package to compute statistics from the American Community Survey (ACS) and Decennial US Census"
description: ""
category: "R"
tags: [ACS, R]
---

```{r, echo=FALSE}
options(replace.assign=TRUE, tidy=TRUE, width=110, scipen = 4, digits = 3)
```

The `acsr` package helps extracting variables and computing statistics using the America Community Survey and Decennial US Census. It was created for the [Applied Population Laboratory](http://www.apl.wisc.edu/) (APL) at the University of Wisconsin-Madison.

<h2 class="section-heading">Installation</h2>

The functions depend on the `acs` and `data.table` packages, so it is necessary to install then before using `acsr`. The `acsr` package is hosted on a github repository and can be installed using `devtools`:

```{r, eval = FALSE}
devtools::install_github("sdaza/acsr")
library(acsr)
```

```{r, echo = FALSE, warning = FALSE, message = FALSE}
library(acsr)
```

Remember to set the ACS API key, to check the help documentation and the default values of the `acsr` functions.

```{r, eval = FALSE}
api.key.install(key="*")
?sumacs
?acsdata
```

The default dataset is `acs`, the level is `state` (Wisconsin, `state = "WI"`), the `endyear` is 2014, and the confidence level to compute margins of error (MOEs) is 90%.

<h2 class="section-heading">Levels</h2>

The `acsr` functions can extract all the levels available in the `acs` package. The table below shows the summary and required levels when using the `acsdata` and `sumacs` functions:

| summary number    | levels                                    |
|----------------   |-----------------------------------------  |
| 010               | us                                        |
| 020               | region                                    |
| 030               | division                                  |
| 040               | state                                     |
| 050               | state, county                             |
| 060               | state, county, county.subdivision         |
| 140               | state, county, tract                      |
| 150               | state, county, tract, block.group         |
| 160               | state, place                              |
| 250               | american.indian.area                      |
| 320               | state, msa                                |
| 340               | state, csa                                |
| 350               | necta                                     |
| 400               | urban.area                                |
| 500               | state, congressional.district             |
| 610               | state, state.legislative.district.upper   |
| 620               | state, state.legislative.district.lower   |
| 795               | state, puma                               |
| 860               | zip.code                                  |
| 950               | state, school.district.elementary         |
| 960               | state, school.district.secondary          |
| 970               | state, school.district.unified            |


<h2 class="section-heading">Getting variables and statistics</h2>

We can use the `sumacs` function to extract variable and statistics. We have to specify the corresponding method (e.g., *proportion* or just *variable*), and the name of the statistic or variable to be included in the output.

```{r}
sumacs(formula = c("(b16004_004 + b16004_026 + b16004_048 / b16004_001)", "b16004_026"),
        varname = c("mynewvar", "myvar"),
        method = c("prop", "variable"),
        level = c("division"))
```

To download the data can be slow, especially when many levels are being used (e.g., blockgroup). A better approach in those cases is, first, download the data using the function `acsdata` , and then use them as input.

```{r}
mydata <- acsdata(formula = c("(b16004_004 + b16004_026 + b16004_048 /  b16004_001)",
        "b16004_026"),
        level = c("division"))

sumacs(formula = c("(b16004_004 + b16004_026 + b16004_048 / b16004_001)", "b16004_026"),
        varname = c("mynewvar", "myvar"),
        method = c("prop", "variable"),
        level = c("division"),
        data = mydata)
```

<h2 class="section-heading">Standard errors</h2>

When computing statistics there are two ways to define the standard errors:

- Including all standard errors of the variables used to compute a statistic (`one.zero = FALSE`)
- Include all standard errors except those of variables that are equal to zero. Only the maximum standard error of the variables equal to zero is included  (`one.zero = TRUE`)
- The default value is `one.zero = TRUE`

For more details about how standard errors are computed for proportions, ratios and aggregations look at [A Compass for Understanding and Using American Community Survey Data](https://www.census.gov/content/dam/Census/library/publications/2008/acs/ACSGeneralHandbook.pdf).

Below an example when estimating proportions and using `one.zero = FALSE`:

```{r, warning=FALSE, message=FALSE}
sumacs(formula = "(b16004_004 + b16004_026 + b16004_048) / b16004_001",
            varname =  "mynewvar",
            method = "prop",
            level = "tract",
            county = 1,
            tract = 950501,
            endyear = 2013,
            one.zero = FALSE)
```

$$ SE = \sqrt{ \frac{(5.47 ^ 2 + 22.49 ^ 2 + 5.47 ^ 2) - ( 0.02 ^ 2 \times 102.13 ^ 2)}{1546} } \times 1.645 = 0.0252 $$

When `one.zero = TRUE`:

```{r, warning=FALSE, message=FALSE}
sumacs(formula = "(b16004_004 + b16004_026 + b16004_048) / b16004_001",
            varname = "mynewvar",
            method = "prop",
            level = "tract",
            county = 1,
            tract = 950501,
            endyear = 2013,
            one.zero = TRUE)
```

$$ SE_{\text{ one.zero}} \sqrt{ \frac{(5.47 ^ 2 + 22.49 ^ 2) - ( 0.02 ^ 2  \times 102.13 ^ 2)}{1546} }  \times 1.645 = 0.0245 $$

When the square root value in the standard error formula doesn't exist (e.g., the square root of a negative number), the ratio formula is instead used. The ratio adjustment is done **variable by variable** .

It can  also be that the `one.zero` option makes the square root undefinable. In those cases, the function uses again the **ratio** formula to compute standard errors. There is also a possibility that the standard error estimates using the **ratio** formula are higher than the **proportion** estimates without the `one.zero` option.

<h2 class="section-heading">Decennial Data from the US Census</h2>

Let's get the African American and Hispanic population by state. In this case, we don't have any estimation of margin of error.

```{r, warning=FALSE, message=FALSE}
sumacs(formula = c("p0080004", "p0090002"),
            method = "variable",
            dataset = "sf1",
            level = "state",
            state = "*",
            endyear = 2010)
```

<h2 class="section-heading">Output</h2>

The output can be formatted using a wide or long format:

```{r }
sumacs(formula = "(b16004_004 + b16004_026 + b16004_048 / b16004_001)",
            varname = "mynewvar",
            method = "prop",
            level = "division",
            format.out = "long")
```

And it can also be exported to a csv file:

```{r}
sumacs(formula = "(b16004_004 + b16004_026 + b16004_048 / b16004_001)",
            varname = "mynewvar",
            method = "prop",
            level = "division",
            file = "myfile.out")
```

<h2 class="section-heading">Combining geographic levels</h2>

We can combine geographic levels using two methods: (1) `sumacs` and (2) `combine.output`. The first one allows only single combinations, the second multiple ones.

If I want to combine two states (e.g., Wisconsin and Minnesota) I can use:

```{r,  warning=FALSE, message=FALSE}
sumacs("(b16004_004 + b16004_026 + b16004_048 / b16004_001)",
    varname = "mynewvar",
    method = "prop",
    level = "state",
    state = list("WI", "MN"),
    combine = TRUE,
    print.levels = FALSE)
```

If I want to put together multiple combinations (e.g., groups of states):

```{r,  warning=FALSE, message=FALSE}
combine.output("(b16004_004 + b16004_026 + b16004_048 / b16004_001)",
    varname = "mynewvar",
    method = "prop",
    level = list("state", "state"),
    state = list( list("WI", "MN"), list("CA", "OR")), # nested list
    combine.names = c("WI+MN", "CA+OR"),
    print.levels = FALSE)
```


<h2 class="section-heading">A map?</h2>

Let's color a map using poverty by county:

```{r,  warning=FALSE, message=FALSE}
pov <- sumacs(formula = "b17001_002 / b17001_001 * 100",
        varname = c("pov"),
        method = c("prop"),
        level = c("county"),
        state = "*")
```

```{r,  warning=FALSE, message=FALSE}
library(choroplethr)
library(choroplethrMaps)
pov[, region := as.numeric(geoid)]
setnames(pov, "pov_est", "value")
county_choropleth(pov, num_colors = 5)
```

In sum, the `acsr` package:

- Reads formulas directly and extracts any ACS/Census variable
- Provides an automatized and tailored way to obtain indicators and MOEs
- Allows different outputs' formats (wide and long, csv)
- Provides an easy way to adjust MOEs to different confidence levels
- Includes a variable-by-variable ratio adjustment of standard errors
- Includes the zero-option when computing standard errors for proportions, ratios, and aggregations
- Combines geographic levels flexibly



**Last Update: `r format(Sys.time(), '%m/%d/%Y')`**
